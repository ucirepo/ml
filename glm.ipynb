{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6cf76",
   "metadata": {
    "id": "b7e6cf76",
    "outputId": "c6235f24-3ea5-432c-bf69-3d221910e838"
   },
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data=pd.read_csv('')\n",
    "\n",
    "# Check the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Preparing the data\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Adding a constant for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Create the GLM model\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3ddc0",
   "metadata": {
    "id": "20c3ddc0"
   },
   "outputs": [],
   "source": [
    "Analysis:\n",
    "\n",
    "    Coefficients (Coef.):\n",
    "Represent the change in the log odds of\n",
    "the outcome for a one-unit change in the\n",
    "predictor variable, holding other variables constant.\n",
    "    P>|z|: P-values associated with the Wald test for each coefficient. Small values (typically <0.05) suggest that a predictor is significantly associated with the outcome variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad8e0d8",
   "metadata": {
    "id": "aad8e0d8"
   },
   "source": [
    "    Dep. Variable: The dependent variable for the model is 'Outcome', which is the binary variable we are trying to predict.\n",
    "\n",
    "    Model: The model used is a GLM.\n",
    "\n",
    "    Model Family: The family is Binomial, indicating that the dependent variable is binary and the model is logistic regression.\n",
    "\n",
    "    Link Function: The link function is Logit, which is commonly used for logistic regression.\n",
    "\n",
    "    No. Observations: There are 768 observations used in fitting the model.\n",
    "\n",
    "    Df Model: The number of predictors (degrees of freedom of the model) is 8, not including the constant term.\n",
    "\n",
    "    Df Residuals: The degrees of freedom for the residuals is 759 (No. Observations - Df Model - 1 for the constant).\n",
    "\n",
    "    Deviance and Pearson chi2: These are goodness-of-fit measures. Lower values generally indicate a better fit.\n",
    "\n",
    "    Covariance Type: The type of covariance used is 'nonrobust', which means that it does not make adjustments for clustering or certain types of heteroskedasticity.\n",
    "\n",
    "    Pseudo R-squ.: The Pseudo R-squared value is 0.2964, which gives an indication of the amount of variance explained by the model. In logistic regression, this value is interpreted differently from the R-squared in linear regression and is generally lower.\n",
    "\n",
    "Coefficients Table:\n",
    "\n",
    "    const: The constant (intercept) has a value of -8.4047. This represents the log-odds of the outcome when all predictors are held at zero.\n",
    "\n",
    "    Pregnancies: The coefficient of 0.1232 suggests that with each additional pregnancy, the log-odds of having diabetes increases by 0.1232, holding other variables constant.\n",
    "\n",
    "    Glucose: A one-unit increase in glucose concentration is associated with an increase in the log-odds of diabetes by 0.0352.\n",
    "\n",
    "    BloodPressure: Blood pressure is slightly negatively associated with the log-odds of diabetes, with a coefficient of -0.0133.\n",
    "\n",
    "    SkinThickness, Insulin, BMI: These variables have coefficients of 0.0006, -0.0012, and 0.0897 respectively, indicating their respective associations with the log-odds of diabetes per unit increase.\n",
    "\n",
    "    DiabetesPedigreeFunction: This has a relatively large positive coefficient of 0.9452, suggesting a strong association with the outcome.\n",
    "\n",
    "    Age: The coefficient of 0.0149 suggests that with each additional year of age, the log-odds of having diabetes increases slightly.\n",
    "\n",
    "Statistical Significance:\n",
    "\n",
    "    P>|z| column: Shows the p-values for the hypothesis tests for each coefficient. A common threshold for significance is 0.05.\n",
    "        For instance, 'Pregnancies', 'Glucose', and 'DiabetesPedigreeFunction' have p-values less than 0.05, indicating that these are statistically significant predictors of diabetes at the 5% significance level.\n",
    "        'BloodPressure' also shows significance with a p-value of 0.011.\n",
    "        Other variables, like 'SkinThickness', 'Insulin', and 'BMI', have p-values greater than 0.05, suggesting they are not statistically significant at the 5% level.\n",
    "\n",
    "    [0.025 0.975] columns: These are the 95% confidence intervals for the coefficients. If the interval for a coefficient does not include zero, it suggests that the predictor is significantly different from zero at the 5% level, reinforcing the findings from the p-values.\n",
    "\n",
    "In summary, the model suggests that the number of pregnancies, glucose level, blood pressure, and diabetes pedigree function are significant predictors of the presence of diabetes, with glucose level and diabetes pedigree function showing the strongest associations. Age is marginally significant. Variables like skin thickness, insulin, and BMI are not statistically significant predictors in this model, according to the p-values provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e63cb",
   "metadata": {
    "id": "348e63cb",
    "outputId": "e5b782ce-2678-4f92-f044-5440eebfd4d4"
   },
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "data=pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print the classification report for further details\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067be129",
   "metadata": {
    "id": "067be129"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
